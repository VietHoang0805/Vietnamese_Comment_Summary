{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T03:40:32.193924Z",
     "iopub.status.busy": "2025-09-09T03:40:32.193576Z",
     "iopub.status.idle": "2025-09-09T03:40:33.317161Z",
     "shell.execute_reply": "2025-09-09T03:40:33.316085Z",
     "shell.execute_reply.started": "2025-09-09T03:40:32.193896Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d631c56cb9c428c8165ad13ed975780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import evaluate\n",
    "metric = evaluate.load(\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T03:42:26.450615Z",
     "iopub.status.busy": "2025-09-09T03:42:26.450339Z",
     "iopub.status.idle": "2025-09-09T03:42:26.932581Z",
     "shell.execute_reply": "2025-09-09T03:42:26.931467Z",
     "shell.execute_reply.started": "2025-09-09T03:42:26.450594Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 1. Load dữ liệu\n",
    "data = pd.read_csv(\"/kaggle/input/vsoslcsum/contents.csv\")\n",
    "summary = pd.read_csv(\"/kaggle/input/vsoslcsum/summaries.csv\")\n",
    "\n",
    "data[\"label_binary\"] = (data[\"label\"] >= 3).atsype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-09T03:47:34.073Z",
     "iopub.execute_input": "2025-09-09T03:45:09.071559Z",
     "iopub.status.busy": "2025-09-09T03:45:09.071271Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 2. Sinh cặp pairwise\n",
    "pairs = []\n",
    "for pid, group in data.groupby(\"post_id\"):\n",
    "    sentences = group.to_dict(\"records\")\n",
    "    for i in range(len(sentences)):\n",
    "        for j in range(len(sentences)):\n",
    "            if sentences[i][\"label\"] > sentences[j][\"label\"]:\n",
    "                pairs.append({\n",
    "                    \"post_id\": pid,\n",
    "                    \"sent_u\": sentences[i][\"text\"],\n",
    "                    \"sent_v\": sentences[j][\"text\"],\n",
    "                    \"label\": 1\n",
    "                })\n",
    "            elif sentences[i][\"label\"] < sentences[j][\"label\"]:\n",
    "                pairs.append({\n",
    "                    \"post_id\": pid,\n",
    "                    \"sent_u\": sentences[i][\"text\"],\n",
    "                    \"sent_v\": sentences[j][\"text\"],\n",
    "                    \"label\": 0\n",
    "                })\n",
    "\n",
    "pairs_df = pd.DataFrame(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 3. Dataset class\n",
    "class PairwiseDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len=128):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        encoded = self.tokenizer(\n",
    "            row[\"sent_u\"],\n",
    "            row[\"sent_v\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoded[\"input_ids\"].squeeze(),\n",
    "            \"attention_mask\": encoded[\"attention_mask\"].squeeze(),\n",
    "            \"labels\": torch.tensor(row[\"label\"], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Load PhoBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=False)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"vinai/phobert-base\", num_labels=2)\n",
    "\n",
    "dataset = PairwiseDataset(pairs_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Training setup\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./phobert-ranking\",\n",
    "    evaluation_strategy=\"epoch\",  \n",
    "    eval_steps=500,               # tính accuracy mỗi 500 steps\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=dataset.sample(frac=0.1, random_state=42),  # dùng 10% để eval\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Sinh summary (inference)\n",
    "def predict_summary(post_id, top_k=6):\n",
    "    group = data[data[\"post_id\"] == post_id]\n",
    "    sentences = group[\"content\"].tolist()\n",
    "    scores = []\n",
    "\n",
    "    for s in sentences:\n",
    "        encoded = tokenizer(\n",
    "            s,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            output = model(**encoded)\n",
    "            score = torch.softmax(output.logits, dim=1)[0][1].item()\n",
    "            scores.append((s, score))\n",
    "\n",
    "    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    return [s for s, _ in scores[:top_k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Đánh giá ROUGE\n",
    "rouge = load_metric(\"rouge\")\n",
    "\n",
    "all_preds, all_refs = [], []\n",
    "for pid, group in summary.groupby(\"post_id\"):\n",
    "    pred_summary = \" \".join(predict_summary(pid, top_k=len(group)))\n",
    "    gold_summary = \" \".join(group[\"content\"].tolist())\n",
    "\n",
    "    all_preds.append(pred_summary)\n",
    "    all_refs.append(gold_summary)\n",
    "\n",
    "results = rouge.compute(predictions=all_preds, references=all_refs)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8231787,
     "sourceId": 13003198,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
